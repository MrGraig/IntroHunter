{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from CNN_search.extract_segments import get_segments"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "cnn = torch.nn.Sequential(*(list(cnn.children())[:-1])).to(device).eval()"
   ],
   "id": "f214246d22be965c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "682d44545dd76a95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_video_features(video_path, t_start, t_end, fps=1):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    current_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_indices = [int((t_start + i) * current_fps) for i in np.arange(0, t_end - t_start,\n",
    "                                                                         1 / fps)]  # Список индексов кадров, которые соответствуют времени внутри сегмента\n",
    "    features = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('Не удалось считать кадр')\n",
    "            continue\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        x = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat = cnn(x).flatten().cpu().numpy()\n",
    "\n",
    "        features.append(feat)\n",
    "\n",
    "    cap.release()\n",
    "    if features:\n",
    "        return np.mean(features, axis=0)  # Итоговый эмбеддинг[512]\n",
    "    else:\n",
    "        return np.zeros(512)"
   ],
   "id": "47eac8e6e90a1105",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class IntroDataset(Dataset):\n",
    "    def __init__(self, samlpes):\n",
    "        self.samlpes = samlpes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samlpes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samlpes[idx]\n",
    "        features = extract_video_features(item['video'], item['t_start'], item['t_end'])\n",
    "        return torch.from_numpy(features).float(), item['label']"
   ],
   "id": "25cd942c92567236",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=512, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(-1)\n"
   ],
   "id": "fbf5c0a9921eaf91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "samples = get_segments('../data/data_train_short/data_train_short/labels.json')",
   "id": "f4ba3babf9a4b4de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = IntroDataset(samples)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)\n",
    "\n",
    "model = Classifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    for feats, labels in tqdm(train_loader):\n",
    "        feats, labels = feats.to(device), labels.float().to(device)\n",
    "        logits = model(feats)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for feats, labels in val_loader:\n",
    "            feats, labels = feats.to(device), labels.float().to(device)\n",
    "            logits = model(feats)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "    p, r, f, _ = precision_recall_fscore_support(all_true, all_preds, average='binary')\n",
    "    print(f\"Epoch {epoch}: Precision={p:.3f}, Recall={r:.3f}, F1={f:.3f}\")"
   ],
   "id": "f44e5a074870c5bd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
